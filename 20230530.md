# 5월 30일

## OpenCV로 QR코드 스캔하기

- 바코드나 QR 코드의 인식을 하기 위해서는 pyzbar가 필요
- pip list | grep wheel 로 원하는 pip의 항목을 꺼내올 수 있음
- pip install pyzbar 로 설치를 해준다. pip list | grep pyzbar로 확인
- sudo apt-get install libzbar0로 pyzbar를 사용할 수 있도록 함
- Scanner.py해서 파일 생성

### QR코드 만들기
- 네이버에서 QR코드 생성 페이지에서 생성
  - 네이버 아이디 필요
- QR코드 생성

![QRCodeImg](https://github.com/ajhwan/OpenCV_study/assets/129160008/4cce71b2-5a6f-4a61-b4a2-e54d4be3f00a)

### python으로 QR코드 불러오기
```python
import cv2
# pyzbar 가져오기
import pyzbar.pyzbar as pyzbar
import matplotlib.pyplot as plt

# 이미지를 불러오기
img = cv2.imread('QR.jpg')

# BRG2GRAY
gary = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 이미지를 확인해보기
# plt.imshow(img)

plt.imshow(gary, cmap='gray')

# matplot 실행하기
plt.show()
```

> 실행 결과

![Screenshot from 2023-05-30 10-38-55](https://github.com/ajhwan/OpenCV_study/assets/129160008/c5de05f3-d95f-401a-a790-52c6d5b2fe33)

```python
import cv2
# pyzbar 가져오기
import pyzbar.pyzbar as pyzbar
import matplotlib.pyplot as plt

# 이미지를 불러오기
img = cv2.imread('QR.jpg')

# BRG2GRAY
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 이미지를 확인해보기
# plt.imshow(img)
plt.imshow(gray, cmap='gray')

# matplot 실행하기
# plt.show()

# pyzbar로 decode를 해주기
decoded = pyzbar.decode(gray)

# decode된 정보확인하기
#print(decoded) 

for d in decoded:
    print(d.type)
    print(d.data.decode('utf-8'))

    cv2.rectangle(gray, (d.rect[0],d.rect[1]),(d.rect[0]+d.rect[2], d.rect[1]+d.rect[3]), (0,0,255), 3)

plt.imshow(gray, cmap='gray')
plt.show()
```
------------------------------------------------------------------------------------------------------------------------------------------------------
```python
cv2.rectangle(gray, (d.rect[0],d.rect[1]),(d.rect[0]+d.rect[2], d.rect[1]+d.rect[3]), (0,0,255), 3)
```
- 위의 코드를 통해 qr코드에 사각형 테두리를 만들어 줌 
>실행 결과

![Screenshot from 2023-05-30 11-03-54](https://github.com/ajhwan/OpenCV_study/assets/129160008/5fab1d2f-1b15-4799-99ec-a546e7e6d2c9)

### 웹캠으로 qr코드 및 바코드 인식하기
```python
import cv2
import pyzbar.pyzbar as pyzbar # pyzbar 가져오기
# import matplotlib.pyplot as plt

cap = cv2.VideoCapture(0) # 카메라 열기
i = 0 # i 의 카운트 숫자 생성

while (cap.isOpened()): # 카메라가 정상 동작을 하였을 경우 실행
    ret, frame = cap.read() # 카메라 불러오기
    if not ret:
        break
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # 화면을 1채널로 변환
    decoded = pyzbar.decode(gray) # pybar 불러오기
    for d in decoded:
        x, y, w, h = d.rect # 좌표값을 x, y, w, h로 할당

        barcode_data = d.data.decode("utf-8") # data 값 불러오기
        barcode_type = d.type # type 불러오기

        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2) # qr, bar사진의 테두리 생성

        text = '%s, %s'%(barcode_data, barcode_type) # 바코드의 데이터와 타입을 text로 지정
        cv2.putText(frame, text, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255),2, cv2.LINE_AA) # 글자 출력

    cv2.imshow("frame", frame) # 화면 출력
    key = cv2.waitKey(1) # key 이벤트 생성

    if key == ord('q'): # 'q'값이 들어올 경우 종료
        break
    elif key == ord('s'): # 's'값이 들어올 경우 imwrite로 캡처
        i += 1 # i 값이 1씩 증가
        cv2.imwrite("C_%03d.png"%i, frame)


cap.release() # 카메라 닫기
cv2.destroyAllWindows() # 창 종료
```

> 실행 결과

![Screenshot from 2023-05-30 11-53-08](https://github.com/ajhwan/OpenCV_study/assets/129160008/145a8d60-12fa-4ad8-ac93-c91193948dbc)


![Screenshot from 2023-05-30 12-17-30](https://github.com/ajhwan/OpenCV_study/assets/129160008/18199f45-b7ad-4699-940a-2a9943213490)

### 웹캠으로 qr코드 인식 후 url로 이동
```python
import cv2
import pyzbar.pyzbar as pyzbar # pyzbar 가져오기
# import matplotlib.pyplot as plt
import webbrowser

cap = cv2.VideoCapture(0)
i = 0
is_website_open = False

while (cap.isOpened()):
    ret, frame = cap.read()
    if not ret:
        break
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    decoded = pyzbar.decode(gray)
    for d in decoded:
        x, y, w, h = d.rect

        barcode_data = d.data.decode("utf-8")
        barcode_type = d.type

        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        text = '%s, %s'%(barcode_data, barcode_type)
        cv2.putText(frame, text, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255),2, cv2.LINE_AA)

        if barcode_data.startswith('http://') or barcode_data.startswith('https://'):
            webbrowser.open(barcode_data)
            is_website_open = True

    cv2.imshow("frame", frame)
    key = cv2.waitKey(1)

    if key == ord('q'):
        break
        
    if is_website_open:
        break

cap.release()
cv2.destroyAllWindows()
```
-----------------------------------------------------------------------------------------------------------------------------------
```python
if barcode_data.startswith('http://') or barcode_data.startswith('https://'):
           webbrowser.open(barcode_data)
           is_website_open = True
```
- webbrower.open을 통해 barcode_data의 데이터를 읽어서 url을 열어줌
- 이후 break 조건을 만들어 줘서 웹브라우저가 열리면 종료 시킴

> 실행 결과

![Screenshot from 2023-05-30 13-14-17](https://github.com/ajhwan/OpenCV_study/assets/129160008/dae9c357-05b3-4a76-83b3-e432982b8e39)

![Screenshot from 2023-05-30 13-14-17-1](https://github.com/ajhwan/OpenCV_study/assets/129160008/b65c76c2-27f1-4652-9539-98d9fc91f306)


## 이미지 뒤틀기
- 어핀 변환 : 어핀 변환은 뒤틀기 방법 중 하나이다.   
        - martix = cv2.getAffineTransform(pts1, pts2)    
                - pts1 : 변환 전 영상의 좌표 3개 , 3 x 2 배열   
                - pts2 : 변환 후 영상의 좌표 3개 , 3 x 2 배열   
                - matrix : 변환 행렬 반환, 2 x 3 행렬
- 원근 변환 : 원근 변환은 이미지를 3차원으로 변환이다.   
        - mtrx = cv2.getPerspectiveTransform(pts1, pts2)   
                - pts1 : 변환 전 영상의 좌표 4개 , 4 x 2 배열   
                - pts2 : 변환 후 영상의 좌표 4개 , 4 x 2 배열   
                - matrix : 변환 행렬 반환, 3 x 3 행렬
```python
import cv2, os
import numpy as np

# 이미지를 불러와서 변수 ori_img에 넣어준다.
img_path = './img/img01.jpg'
ori_img = cv2.imread('./img/img01.jpg')
filename, ext = os.path.splitext(os.path.basename(img_path))
src = []

# mouse callback function
def onMouse(event, x, y, flags, param):
    # 마우스 좌측 버튼
    if event == cv2.EVENT_LBUTTONUP:
        img = ori_img.copy()
        # src에 x, y값을 저장한다.
        src.append([x, y])
        for xx, yy in src:
            cv2.circle(img, center=(xx, yy), radius=5, color=(0, 255, 0), thickness=-1, lineType=cv2.LINE_AA)
        cv2.imshow('img', img)

        # Perspective transform
        if len(src) == 4:
            src_np = np.array(src, np.float32)

            width = max(np.linalg.norm(src_np[0] - src_np[1]), np.linalg.norm(src_np[2] - src_np[3]))
            height = max(np.linalg.norm(src_np[0] - src_np[3]), np.linalg.norm(src_np[1] - src_np[2]))

            dst_np = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype=np.float32)

            # dst_np와 src_np의 값을 getPerspectiveTransform에 넣어준다.
            M = cv2.getPerspectiveTransform(src=src_np, dst=dst_np)
            # M의 값을 warpPerspectived에 넣어준다. 
            result = cv2.warpPerspective(ori_img, M=M, dsize=(int(width), int(height)))

            cv2.imshow('result', result)
            cv2.imwrite('%s_result%s' % (filename, ext), result)

        # 마우스 좌측 버튼을 4번 클릭하면 초기화
        if len(src) == 4:
            src.clear()

# 윈도우에 이름을 지정해주기
cv2.namedWindow('img')

# img라고 지정된 윈도우에 마우스콜백함수를 지정해줘서 마우스 동작이 있으면 onMouse를 동작한다.
cv2.setMouseCallback('img', onMouse)

cv2.imshow('img', ori_img)  # 이미지 띄우기
cv2.waitKey(0)
cv2.destroyAllWindows()
```

> 실행 결과

![Screenshot from 2023-05-30 15-38-03](https://github.com/ajhwan/OpenCV_study/assets/129160008/726a688a-624e-4c1d-8060-4fb9c7fdb581)

> 오류
- 점을 한 방향으로만 찍어야하는 오류가 있음

![Screenshot from 2023-05-30 15-41-32](https://github.com/ajhwan/OpenCV_study/assets/129160008/dc1791cf-7a95-4bb0-92dd-e43a0f3fa0c9)

- 한 방향으로 찍지 않으면 위의 사진과 같은 오류가 생김

#### 이미지 뒤틀기 오류 해결
```python
import cv2
import numpy as np

win_name = "scanning"
img = cv2.imread('./img/img01.jpg')
rows, cols = img.shape[:2]
draw = img.copy()
pts_cnt = 0
pts = np.zeros((4,2), dtype=np.float32)

def onMouse(event, x, y, flags, param):  #마우스 이벤트 콜백 함수 구현
    global  pts_cnt                     # 마우스로 찍은 좌표의 갯수 저장
    if event == cv2.EVENT_LBUTTONDOWN:  
        cv2.circle(draw, (x,y), 5, (0,255,0), -1) # 좌표에 초록색 동그라미 표시
        cv2.imshow(win_name, draw)

        pts[pts_cnt] = [x,y]            # 마우스 좌표 저장
        pts_cnt+=1
        if pts_cnt == 4:                       # 좌표가 4개 수집됨 
            # 좌표 4개 중 상하좌우 찾기
            sm = pts.sum(axis=1)                 # 4쌍의 좌표 각각 x+y 계산
            diff = np.diff(pts, axis = 1)       # 4쌍의 좌표 각각 x-y 계산

            topLeft = pts[np.argmin(sm)]         # x+y가 가장 값이 좌상단 좌표
            bottomRight = pts[np.argmax(sm)]     # x+y가 가장 큰 값이 좌상단 좌표
            topRight = pts[np.argmin(diff)]     # x-y가 가장 작은 것이 우상단 좌표
            bottomLeft = pts[np.argmax(diff)]   # x-y가 가장 큰 값이 좌하단 좌표

            # 변환 전 4개 좌표 
            pts1 = np.float32([topLeft, topRight, bottomRight , bottomLeft])

            # 변환 후 영상에 사용할 이미지의 폭과 높이 계산
            w1 = abs(bottomRight[0] - bottomLeft[0])    # 상단 좌우 좌표간의 거리
            w2 = abs(topRight[0] - topLeft[0])          # 하당 좌우 좌표간의 거리
            h1 = abs(topRight[1] - bottomRight[1])      # 우측 상하 좌표간의 거리
            h2 = abs(topLeft[1] - bottomLeft[1])        # 좌측 상하 좌표간의 거리
            width = max([w1, w2])                       # 두 좌우 거리간의 최대값이 이미지의 폭
            height = max([h1, h2])                      # 두 상하 거리간의 최대값이 이미지의 높이
            
            # 변환 후 4개 좌표
            pts2 = np.float32([[0,0], [width-1,0], 
                                [width-1,height-1], [0,height-1]])

            # 변환 행렬 계산 
            mtrx = cv2.getPerspectiveTransform(pts1, pts2)
            # 원근 변환 적용
            result = cv2.warpPerspective(img, mtrx, (int(width), int(height)))
            cv2.imshow('scanned', result)
cv2.imshow(win_name, img)
cv2.setMouseCallback(win_name, onMouse)    # 마우스 콜백 함수를 GUI 윈도우에 등록
cv2.waitKey(0)
cv2.destroyAllWindows()
```
----------------------------------------------------------------------------------------------------------------------------------------------------------------
```python
sm = pts.sum(axis=1)                 # 4쌍의 좌표 각각 x+y 계산
diff = np.diff(pts, axis = 1)       # 4쌍의 좌표 각각 x-y 계산

topLeft = pts[np.argmin(sm)]         # x+y가 가장 값이 좌상단 좌표
bottomRight = pts[np.argmax(sm)]     # x+y가 가장 큰 값이 좌상단 좌표
topRight = pts[np.argmin(diff)]     # x-y가 가장 작은 것이 우상단 좌표
bottomLeft = pts[np.argmax(diff)]   # x-y가 가장 큰 값이 좌하단 좌표
```
- 이전 코드에서는 4개의 점을 찍을 때 상하좌우를 따지지 않고 코드를 구현함
- 위의 코드를 사용하여 4개의 점을 찍는 좌표의 시작점과 순서에 상관없이 상하좌우를 구분할 수 있도록 구현
----------------------------------------------------------------------------------------------------------------------------------------------------------------
```python
w1 = abs(bottomRight[0] - bottomLeft[0])    # 상단 좌우 좌표간의 거리
w2 = abs(topRight[0] - topLeft[0])          # 하당 좌우 좌표간의 거리
h1 = abs(topRight[1] - bottomRight[1])      # 우측 상하 좌표간의 거리
h2 = abs(topLeft[1] - bottomLeft[1])        # 좌측 상하 좌표간의 거리
width = max([w1, w2])                       # 두 좌우 거리간의 최대값이 이미지의 폭
height = max([h1, h2])                      # 두 상하 거리간의 최대값이 이미지의 높이
```
- 위의 코드를 이용해서 지정한 범위 내의 이미지의 변환구간을 지정(이미지의 폭과 높이를 지정)
> 실행 결과

![Screenshot from 2023-05-30 15-50-41](https://github.com/ajhwan/OpenCV_study/assets/129160008/1424d707-d6af-4483-bfb8-dfa4702332c2)
- 점을 찍는 순서에 상관없이 오류가 없이 잘 출력됨

### 이미지 이어붙이기(파라노마)
```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

import os, glob

IMG_NAME = 'boat'

img_list = []
for ext in ('0*.jpg','0*.png'):
    img_list.extend(glob.glob(os.path.join('imgs',IMG_NAME, ext)))

img_list = sorted(img_list)

# print(img_list)

imgs = []

plt.figure(figsize=(20,20))

for i, img_path in enumerate(img_list):
    img = cv2.imread(img_path)
    imgs.append(img)

    plt.subplot(len(img_list) // 3+1, 3, i+1)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

#plt.show()
mode = cv2.STITCHER_PANORAMA

if int(cv2.__version__[0]) == 3:
    stitcher = cv2.createStitcher(mode)
else:
    stitcher = cv2.Stitcher_create(mode)

status, stitched = stitcher.stitch(imgs)

if status == 0:
    cv2.imwrite(os.path.join('img', IMG_NAME, 'result.jpg'), stitched)
    
    plt.figure(figsize=(20, 20))
    plt.imshow(cv2.cvtColor(stitched, cv2.COLOR_BGR2RGB))
else:
    print('failed..%s' % status)

plt.show()
```

> 실행 결과

![Screenshot from 2023-05-30 16-42-28](https://github.com/ajhwan/OpenCV_study/assets/129160008/8316dde6-a3b3-4734-976a-b27909cbcb4a)

![Screenshot from 2023-05-30 16-53-20](https://github.com/ajhwan/OpenCV_study/assets/129160008/c8494ff5-0311-4834-af54-373844fdae24)

---------------------------------------------------------------------------------------------------------------------------------------------------------------
```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

import os, glob

IMG_NAME = 'boat'

# 다량의 이미지 얻기
img_list = []
for ext in ('0*.jpg','0*.png'):
    img_list.extend(glob.glob(os.path.join('imgs',IMG_NAME, ext)))

img_list = sorted(img_list)

# print(img_list)

# 다량의 이미지를 얻어 불러와 출력하기
imgs = []

plt.figure(figsize=(20,20))

for i, img_path in enumerate(img_list):
    img = cv2.imread(img_path)
    imgs.append(img)

    plt.subplot(len(img_list) // 3+1, 3, i+1)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

#plt.show()
# 여러 이미지를 하나의 이미지로 붙여서 만들기
mode = cv2.STITCHER_PANORAMA

if int(cv2.__version__[0]) == 3:
    stitcher = cv2.createStitcher(mode)
else:
    stitcher = cv2.Stitcher_create(mode)

status, stitched = stitcher.stitch(imgs)

if status == 0:
    cv2.imwrite(os.path.join('img', IMG_NAME, 'result.jpg'), stitched)
    
    plt.figure(figsize=(20, 20))
    plt.imshow(cv2.cvtColor(stitched, cv2.COLOR_BGR2RGB))
else:
    print('failed..%s' % status)

# plt.show()

# 붙인 이미지의 테두리의 검은색의 부분을 추출하기
gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY)
thresh = cv2.bitwise_not(cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1])
thresh = cv2.medianBlur(thresh, 5) # 선명도 처리

plt.figure(figsize=(20,20))
plt.imshow(thresh, cmap='gray')

# plt.show()

# 테두리의 검은 색부분을 없애 온전한 한 컷으로 만들기
stitched_copy = stitched.copy()
thresh_copy = thresh.copy()

while np.sum(thresh_copy) > 0:
    thresh_copy = thresh_copy[1:-1, 1:-1]
    stitched_copy = stitched_copy[1:-1, 1:-1]

cv2.imwrite(os.path.join('imgs', IMG_NAME, 'result_crop.jpg'), stitched_copy)    

plt.figure(figsize=(20,20))
plt.imshow(cv2.cvtColor(stitched_copy, cv2.COLOR_BGR2RGB))

plt.show()
```

![Screenshot from 2023-05-30 16-59-17](https://github.com/ajhwan/OpenCV_study/assets/129160008/a6c2d032-2462-40a0-a556-cd46770d2ca4)

![Screenshot from 2023-05-30 17-08-58](https://github.com/ajhwan/OpenCV_study/assets/129160008/3bb8bdd0-bdac-4895-81be-15dcf6ca832a)

