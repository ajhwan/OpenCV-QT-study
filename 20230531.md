# 5월 31일

## 투명망토 만들기
- 비디오 설정 후 배경이미지 캡쳐
- 카메라 열고 웹캠으로 읽기
- Color segmentation으로 크로마키할 색을 설정
- 원하는 색을 제거하기
 
```python
# import
import cv2
import numpy as np
import time, argparse

# 비디오
parser = argparse.ArgumentParser()
parser.add_argument('--video', help='Input video path')
args = parser.parse_args()

cap = cv2.VideoCapture(args.video if args.video else 0)
time.sleep(3)

# 1- 배경이미지 캡쳐
for i in range(60):
    ret, background=cap.read()
# 동여상을 저장하기 위한 코드
fourcc = cv2.VideoWriter_fourcc('m','p','4','v')
# 출력 비디오 파일의 세팅
out = cv2.VideoWriter('videos/output.mp4', fourcc, cap.get(cv2.CAP_PROP_FPS), (background.shape[1], background.shape[0]))
out2 = cv2.VideoWriter('videos/output.mp4', fourcc, cap.get(cv2.CAP_PROP_FPS), (background.shape[1], background.shape[0]))

# 2- 카메라 열고 읽기
while(cap.isOpened()):
    # 카메라로 읽어들인 것을 img에 저장
    ret, img = cap.read()
    if not ret:
        break

    # BRG -> HSV
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    # red를 확인하기 위한 마스킹 작업    
    # color segmentation - mask
    lower_red = np.array([0, 120, 70])
    upper_red = np.array([10, 255, 255])
    mask1 = cv2.inRange(hsv, lower_red, upper_red)

    lower_red = np.array([130, 120, 70])
    upper_red = np.array([180, 255, 255])
    mask2 = cv2.inRange(hsv, lower_red, upper_red)

    mask1 = mask1 + mask2 # 빨간색을 다 mask한 마스크가 탄생
    # 노이즈 제거하기
    
    # Remove noise - 마스크를 색만 뽑으면 노이즈가 발생해서 정제해주는 함수
    mask_cloak = cv2.morphologyEx(mask1, op=cv2.MORPH_OPEN, kernel=np.ones((3,3), np.uint8), iterations=2)
    mask_cloak = cv2.dilate(mask_cloak, kernel=np.ones((3,3), np.uint8), iterations=1)
    mask_bg = cv2.bitwise_not(mask_cloak)

    cv2.imshow('mask_cloak', mask_cloak)
    # 최종 결과물 만들기
    res1 = cv2.bitwise_and(background, background, mask=mask_cloak)  # background에서 mask만 남음
    res2 = cv2.bitwise_and(img, img, mask=mask_bg) # 캠으로 들어오는 이미지에서 mask가 안 된 부분만 남음
    result = cv2.addWeighted(src1=res1, alpha=1, src2=res2, beta=1, gamma=0)

    cv2.imshow('res1', res1)

    cv2.imshow('result', result)
    out.write(result)
    out2.write(img)

    if cv2.waitKey(1) == ord('q'):
        break

out.release()
out2.release()
cap.release()
```
- 붉은색에 대한 HSV 값을 찾아서 코드에 적용시키 웹캠에 붉은색이 잡히면 크로마키처럼 실행
    - 빨간색의 범위는 0~10 170~180이라 두 개로 나누어 마스크 생성 후 더함
-  cv2.inRange() : 범위 안에 해당하는 값들로 마스크를 생성
-  bitwise_and() : AND연산을 통해 두개의 행렬이 0이 아닌 것만 통과되어 마스크 영역만 남음
-  cv2.addWeighted() : 두 개의 이미지를 합친다 
> 실행 결과

- 빨간색을 크로마키한 경우

![Screenshot from 2023-05-31 11-41-08](https://github.com/ajhwan/OpenCV_study/assets/129160008/6183d1e3-0354-4696-a4f4-6cc7f3255ce2)

- 검은색을 크로마키한 경우

![Screenshot from 2023-05-31 11-39-47](https://github.com/ajhwan/OpenCV_study/assets/129160008/3d85a124-f2f3-4b58-a6f8-028f4458be59)

## 이미지 모자이크
- 1. 이미지를 가져오고 사이즈를 조정
- 2. 조각에 맞는 이미지를 미리 확인
- 3. 픽셀의 분포 확인
- 4. 글씨 이미지와 고양이 픽셀 이미지 매칭
- 5. 그림을 채워주기
```python
import cv2, os
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict

# 과정
# 1 - 이미지를 가져오고 사이즈를 조정
img_path = 'img/09.jpg'
img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
img = cv2.resize(img, dsize=None, fx=0.2, fy=0.2) # 픽셀이 너무 많으면 조각을 찾는 과정이 오래걸려서 최대한 축소시기키 위함
# print(img.shape)
# plt.figure(figsize=(20,20))
# plt.axis('off')
# plt.imshow(img,cmap='gray')
# plt.show()
# 2 - 조각에 맞는 이미지를 미리 확인
sample_imgs = np.load('dataset/k49-train-imgs.npz')['arr_0']
# plt.figure(figsize=(20,10))
# for i in range(80):
#     img_patch = 255 - sample_imgs[i]
#     plt.subplot(5, 16, i+1)
#     plt.title(int(np.mean(img_patch)))
#     plt.axis('off')
#     plt.imshow(img_patch, cmap='gray')
# plt.show()
# 3 - 픽셀의 분포 확인
means = np.mean(255- sample_imgs, axis=(1,2))
# plt.figure(figsize=(12,6))
# plt.hist(means, bins=50, log=True)
# plt.show()

img = cv2.normalize(img, dst=None, alpha=120, beta=245, norm_type=cv2.NORM_MINMAX)
# plt.figure(figsize=(12,6))
# plt.hist(img.flatten(), bins=50, log=True)
# plt.show()
# 4 - 글씨 이미지와 고양이 픽셀이미지 매칭
bins = defaultdict(list)

for img_patch, mean in zip(sample_imgs, means):
    bins[int(mean)].append(img_patch)

print(len(bins))
# 5 - 채우기
h, w = img.shape
img_out = np.zeros((h*28, w*28), dtype=np.uint8)
for y in range(h):
    for x in range(w):
        level = img[y,x]
        b = bins[level]
        while len(b) == 0:
            level +=1
            b = bins[level]
        img_patch = 255 - b[np.random.randint(len(b))]
        img_out[y*28:(y+1)*28, x*28:(x+1)*28] = img_patch
plt.figure(figsize=(20,20))
plt.axis('off')
plt.imshow(img_out, cmap='gray')
plt.show()
```
> 실행 결과
### 이미지를 가져오고 사이즈를 조정
```python
img = cv2.resize(img, dsize=None, fx=0.2, fy=0.2)
print(img.shape)
plt.figure(figsize=(20,20))
plt.axis('off')
plt.imshow(img,cmap='gray')
plt.show()
```
![Screenshot from 2023-05-31 14-44-30](https://github.com/ajhwan/OpenCV_study/assets/129160008/566d1961-22ff-4224-93b8-6cf15b6cfbcc)

### 조각에 맞는 이미지를 미리 확인

```python
sample_imgs = np.load('dataset/k49-train-imgs.npz')['arr_0']
plt.figure(figsize=(20,10))
for i in range(80):
    img_patch = 255 - sample_imgs[i]
    plt.subplot(5, 16, i+1)
    plt.title(int(np.mean(img_patch)))
    plt.axis('off')
    plt.imshow(img_patch, cmap='gray')
plt.show()
```
![Screenshot from 2023-05-31 14-53-43](https://github.com/ajhwan/OpenCV_study/assets/129160008/2612687d-50ac-4132-be7d-2e8c749cbbb0)

### 픽셀의 분포 확인

```python
means = np.mean(255- sample_imgs, axis=(1,2))
plt.figure(figsize=(12,6))
plt.hist(means, bins=50, log=True)
plt.show()

img = cv2.normalize(img, dst=None, alpha=120, beta=245, norm_type=cv2.NORM_MINMAX)
plt.figure(figsize=(12,6))
plt.hist(img.flatten(), bins=50, log=True)
plt.show()
```
![Screenshot from 2023-05-31 14-54-16](https://github.com/ajhwan/OpenCV_study/assets/129160008/b1f5f5ea-a314-46fe-bf5b-bd7d48ad8c7f)

![Screenshot from 2023-05-31 14-59-32](https://github.com/ajhwan/OpenCV_study/assets/129160008/6cbb68c7-e49c-4efb-8dce-ff32ae10bb56)

### 글씨 이미지와 고양이 픽셀 이미지 매칭 및 그림을 채워주기
```python
bins = defaultdict(list)

for img_patch, mean in zip(sample_imgs, means):
    bins[int(mean)].append(img_patch)

print(len(bins))
h, w = img.shape
img_out = np.zeros((h*28, w*28), dtype=np.uint8)
for y in range(h):
    for x in range(w):
        level = img[y,x]
        b = bins[level]
        while len(b) == 0:
            level +=1
            b = bins[level]
        img_patch = 255 - b[np.random.randint(len(b))]
        img_out[y*28:(y+1)*28, x*28:(x+1)*28] = img_patch
plt.figure(figsize=(20,20))
plt.axis('off')
plt.imshow(img_out, cmap='gray')
plt.show()
```
![Screenshot from 2023-05-31 15-10-54](https://github.com/ajhwan/OpenCV_study/assets/129160008/16094aa9-133b-4f3c-a5e5-80b101602e1f)

- img_path, 과 sample_imgs의 데이터를 수정하여 다른 사진의 결과값을 확인 할 수 있다.
- cv2.normalize를 통해서 흑, 백의 분포도를 원하는 범위로 간추려 줄 수 있다.
- defaultdict 에서 patch이미지를 평균값에 맞춰서 bins에 딕셔너릴로 정리한다.
- for문을 반복으로 돌면서 레벨에 해당되는 이미지를 채워 넣는다.
- 이미지들 중에 랜덤으로 뽑아서 img_patch라는 변수에 넣는다.

## 이미지 매칭
```python
import cv2

img = cv2.imread('./img/pistol.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

gray = cv2.resize(gray, (16,16))
avg = gray.mean()
bin = 1 * (gray > avg)
print(bin)
```

> 실행 결과

![Screenshot from 2023-05-31 16-34-50](https://github.com/ajhwan/OpenCV_study/assets/129160008/b0bc1ed5-65f7-4f3f-a22c-7741f773a12a)

- 위의 사진이 아래처럼 변환됨 
 - 밝은 부분을 '1'로 어두운 부분을 '0'으로 표현
 
![Screenshot from 2023-05-31 16-34-14](https://github.com/ajhwan/OpenCV_study/assets/129160008/d58c3cd5-3ec2-4b85-ba48-6f77d613225c)

### 이미지 나타내기
```python
dhash = []
for row in bin.tolist():
    s = ''.join([str(i) for i in row])
    dhash.append('%02x'%(int(s,2)))
dhash = ''.join(dhash)    
print(dhash)

cv2.namedWindow('pistol', cv2.WINDOW_GUI_NORMAL)
cv2.imshow('pistol', img)
cv2.waitKey(0)
```

> 실행 결과

![Screenshot from 2023-05-31 16-42-52](https://github.com/ajhwan/OpenCV_study/assets/129160008/f0aebb2c-5bed-4aa5-831c-18d0cde6a45d)





