# 6월 2일

## 얼굴 검출하기
- dlib : C++로 작성됨 범용 크로스 플랫폼 소프트웨어 라이브러리
- 얼굴을 우선적으로 잡고, 대략적인 위치를 정하고, 대략적인 위치의 좌표를 정해준다.

> - git clone -b test --single-branch https://github.com/AntonSangho/annoying-orange-face.git 로 파일받아오기
> - https://github.com/davisking/dlib-models/blob/master/shape_predictor_68_face_landmarks.dat.bz2 파일 받아오기
> - 사용하고자하는 annoying-orange-face에 bz2파일을 옮긴다.
> - bunzip2 shape_predictor_68_face_landmarks.dat.bz2 로 압축을 풀어준다.

- 과일 이미지 크기조절
- 데이터 셋을 가져오기
- 카메라를 열고, 인식을 해준다.
- 얼굴 인식을 해주고, 눈, 입을 인식한다.
- 인식 데이터를 crop으로 오려주고, 합성을 한다.(cv2.seamlessClone)

```python
import cv2
import numpy as np
import dlib
from imutils import face_utils, resize

# orange_img = cv2.imread('orange.jpg')
orange_img = cv2.imread('apple.jpg')
orange_img = cv2.resize(orange_img, dsize = (512, 512))

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')

# cam version
cap = cv2.VideoCapture(0)
# video version
# cap = cv2.VideoCapture('01.mp4')

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    # face selated from frame
    face = detector(frame)
    result = orange_img.copy()

    # face is over ones
    if len(face) > 0:
        face = face[0]
        # face of left, rigth, top, bottom is save
        x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()
        # just face copyright
        face_img = frame[y1: y2, x1: x2].copy()

        shape = predictor(frame, face)
        shape = face_utils.shape_to_np(shape)

        for p in shape:
            cv2.circle(face_img, center = (p[0]-x1, p[1]-y1), radius=2, color=255, thickness=-1)

        # left eye
        le_x1 = shape[36, 0]
        le_y1 = shape[37, 1]
        le_x2 = shape[39, 0]
        le_y2 = shape[41, 1]

        le_margin = int((le_x2 - le_x1) * 0.18)

        # right eye
        re_x1 = shape[42, 0]
        re_y1 = shape[43, 1]
        re_x2 = shape[45, 0]
        re_y2 = shape[47, 1]

        re_margin = int((re_x2 - re_x1) * 0.18)

        # Crop
        left_eye_img = frame[le_y1-le_margin: le_y2+le_margin, le_x1-le_margin: le_x2+le_margin].copy()
        right_eye_img = frame[re_y1-re_margin: re_y2+re_margin, re_x1-re_margin: re_x2+re_margin].copy()

        left_eye_img = resize(left_eye_img, width=100)
        right_eye_img = resize(right_eye_img, width=100)

        # poison blending
        result = cv2.seamlessClone(left_eye_img, result, np.full(left_eye_img.shape[:2], 255, left_eye_img.dtype), (200, 200), cv2.MIXED_CLONE)
        result = cv2.seamlessClone(right_eye_img, result, np.full(right_eye_img.shape[:2], 255, right_eye_img.dtype), (350, 200), cv2.MIXED_CLONE)


        # mouse
        mouse_x1 = shape[48, 0]
        mouse_y1 = shape[50, 1]
        mouse_x2 = shape[54, 0]
        mouse_y2 = shape[57, 1]

        mouse_margin = int((mouse_x2 - mouse_x1) * 0.1)
        mouse_img = frame[mouse_y1-mouse_margin: mouse_y2+mouse_margin, mouse_x1-mouse_margin: mouse_x2+mouse_margin].copy()
        mouse_img = resize(mouse_img, width=250)
        result = cv2.seamlessClone(mouse_img, result, np.full(mouse_img.shape[:2], 255, mouse_img.dtype), (280, 320), cv2.MIXED_CLONE)

        # cv2.imshow('left eye', left_eye_img)
        # cv2.imshow('right eye', right_eye_img)
        # cv2.imshow('mouse', mouse_img)
        cv2.imshow('result', result)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
```
- imutils 가 없는경우 pip3 install imutils로 설치를 해준다.

> 실행 결과
- 오렌지로 했을 때

![Screenshot from 2023-06-02 12-06-19](https://github.com/ajhwan/OpenCV_study/assets/129160008/7bf3fcd2-efc7-44f1-a6a2-622a713c457c)

- 사과로 했을 때

![Screenshot from 2023-06-02 12-10-15](https://github.com/ajhwan/OpenCV_study/assets/129160008/f36dc081-a087-4561-8e87-dfa328453fc2)


