# 6월 20일

## 미니콘다 설치(우분투)
- 출처 : https://webnautes.tistory.com/1499
1. 설치스크립트 다운로드
> - wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
2. 설치스크립트에 권한설정
> - chmod +x Miniconda3-latest-Linux-x86_64.sh
3. 설치스크립트 실행
> - ./Miniconda3-latest-Linux-x84_64.sh
4. 설치진행시 설정은 기본값으로 지정 (모두 엔터, yes) (기본 설치경로 /home/계정/miniconda3)
5. 나노에디터로 연 bashrc 가장 아래 추가 (Ctrl+o 저장, Ctrl+x 닫기)
> - nano ~/.bashrc로 열고
> - export PATH=~/miniconda3/bin:sPATH (맨 아래 추가)
6. 환경변수를 바로 반영되도록 설정
> - source ~/.bashrc
7. (base)$ 로 표시되면 설정완료
8. (base)$ conda config -set auto_activate_base false
9. conda 비활성화
> - (base)$ conda deactivate
10. conda 활성화
> - (base)$ conda activate
11. conda 가상환경 생성
> - conda create -n newenv python=3.8
12. conda 가상환경 조회
> - conda env list
13. newenv 가상환경을 활성화
> - conda activate newenv
14. 패키지 설치 명령
> - conda install 패키지명
> - pip3 install 패키지명
15. conda-forge 저장소를 이용
> - conda install -c conda-forge 패키지명
16. 가상환경 삭제 방법
> - conda env remove -n newenv
17. conda 설치가능한 파이썬 버전 검색
> - conda search python
18. conda 원하는 바전의 파이선으로 변경
> - conda install python=3.8.11 


## TensorFlow 및 OpenCV, matplotlib 설치
1. TensorFlow 설치
> - (newenv)$ pip install tensorflow
2. OpenCV 설치
> - (newenv)$ pip install opencv-contrib-python
3. matplotlib 설치
> - (newenv)$ pip install matplotlib

## Teachable Machine으로 만든 데이터 셋을 conda 가상환경에서 실행하기
```python
from keras.models import load_model  # TensorFlow is required for Keras to work
import cv2  # Install opencv-python
import numpy as np
import tensorflow as tf

# Disable scientific notation for clarity
np.set_printoptions(suppress=True)

# Load the model
model = load_model("./res/keras_model.h5", compile=False)

# Load the labels
class_names = open("./res/labels.txt", "r").readlines()

# CAMERA can be 0 or 1 based on default camera of your computer
camera = cv2.VideoCapture(2)

while True:
    # Grab the webcamera's image.
    ret, image = camera.read()

    # Resize the raw image into (224-height,224-width) pixels
    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)

    # Show the image in a window
    cv2.imshow("Webcam Image", image)

    # Make the image a numpy array and reshape it to the models input shape.
    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)

    # Normalize the image array
    image = (image / 127.5) - 1

    # Predicts the model
    prediction = model.predict(image)
    index = np.argmax(prediction)
    class_name = class_names[index]
    confidence_score = prediction[0][index]

    # Print prediction and confidence score
    print("Class:", class_name[2:], end="")
    print("Confidence Score:", str(np.round(confidence_score * 100))[:-2], "%")

    # Listen to the keyboard for presses.
    keyboard_input = cv2.waitKey(1)

    # 27 is the ASCII for the esc key on your keyboard.
    if keyboard_input == 27:
        break

camera.release()
cv2.destroyAllWindows()
```

> 실행 결과

- 바위

![Screenshot from 2023-06-20 14-27-00](https://github.com/ajhwan/OpenCV_study/assets/129160008/8a0ca5cb-3c1c-4ecb-add7-deb9e1ae502a)
![Screenshot from 2023-06-20 14-27-06](https://github.com/ajhwan/OpenCV_study/assets/129160008/21f09bc7-75ae-4525-b5de-412ab3d16444)

- 가위

![Screenshot from 2023-06-20 14-26-45](https://github.com/ajhwan/OpenCV_study/assets/129160008/60f747d9-9662-4106-b342-efd79cc8bd40)
![Screenshot from 2023-06-20 14-26-52](https://github.com/ajhwan/OpenCV_study/assets/129160008/4801b57a-5382-43f4-8fd5-586be8dce941)

- 보

![Screenshot from 2023-06-20 14-27-12](https://github.com/ajhwan/OpenCV_study/assets/129160008/21d1a1c0-c530-4694-a3d4-a14c731529b8)
![Screenshot from 2023-06-20 14-27-20](https://github.com/ajhwan/OpenCV_study/assets/129160008/cdc13ea7-e76d-4ef8-805c-51b9fc35f018)
