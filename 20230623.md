# 6월 23일

## youtube 동영상 불러와서 YOLO 적용하기
```python
import torch
import cv2
from cap_from_youtube import cap_from_youtube

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

model = torch.hub.load('ultralytics/yolov5', "yolov5s")
model.to(device) #현재 기본은 cuda
classNames = model.names

url = "https://www.youtube.com/watch?v=h3glVQbTmks"
cap = cap_from_youtube(url, '480p')
fps = cap.get(cv2.CAP_PROP_FPS) # ex: 30fps, 60fps
mfps = int(1000/fps)  # ex: 16ms, 30ms
print('frameRate: ', fps)
print('mfps: ', mfps)

while cap.isOpened():
    ret, frame = cap.read()

    if ret:
        # 프레임을 읽어와 표시(합성된 결과)

        # 해당 프레임을 yolo를 활용해 파악
        predict = model(frame)

        labels = predict.xyxyn[0][:,-1].cpu().numpy()
        cord = predict.xyxyn[0][:,:-1].cpu().numpy()


        # 결과를 프레임과 합성
        fy, fx = frame.shape[:2]

        labelNum = len(labels)
        for i in range(labelNum):
            # row => 해당 행의 값들이 담겨있음
            row = cord[i]
            x = row[4]
            if x >= 0.2:
                # 0.5 * 1080 = 540 = x1
                x1 = int(row[0]*fx)
                y1 = int(row[1]*fy)
                x2 = int(row[2]*fx)
                y2 = int(row[3]*fy)

                labelStr = '{}, ({},{}), {}'.format(
                                classNames[int(labels[i])],
                                x1,y1,
                                str(row[4])[:4]
                            )
                
                cv2.rectangle(frame, (x1,y1,x2,y2), (0,255,0), 2)
                cv2.putText(frame, labelStr, 
                            (x1,y1), cv2.FONT_HERSHEY_SIMPLEX, 1, 
                            (0,0,255), 2)
                
        cv2.imshow('dst', frame)

    if cv2.waitKey(mfps) == 27:
        break

cap.release()
cv2.destroyAllWindows()
```
- 'cap_from_youtube'에서 오류가 날 때 (KeyError: 'format_note')
- cap_from_youtube.py 파일을 수정
> - self.resolution = video_format['format_note'] (이 한줄을 주석처리 시키고)
> - self.resolution = video_format.get('format_note', '') (바로 아래줄에 집어넣기)

> 실행 결과

![ase](https://github.com/ajhwan/OpenCV_study/assets/129160008/d48bc9c1-c625-45fa-a237-d616bcc320a9)


## 웹캠으로 YOLO 적용하기
```python
import torch
import cv2
from cap_from_youtube import cap_from_youtube

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

model = torch.hub.load('ultralytics/yolov5', "yolov5s")
model.to(device) #현재 기본은 cuda
classNames = model.names

url = "https://www.youtube.com/watch?v=h3glVQbTmks"

# cap = cap_from_youtube(url, '480p')
cap = cv2.VideoCapture(0)
fps = cap.get(cv2.CAP_PROP_FPS) # ex: 30fps, 60fps
mfps = int(1000/fps)  # ex: 16ms, 30ms
print('frameRate: ', fps)
print('mfps: ', mfps)

while cap.isOpened():
    ret, frame = cap.read()

    if ret:
        # 프레임을 읽어와 표시(합성된 결과)

        # 해당 프레임을 yolo를 활용해 파악
        predict = model(frame)

        labels = predict.xyxyn[0][:,-1].cpu().numpy()
        cord = predict.xyxyn[0][:,:-1].cpu().numpy()


        # 결과를 프레임과 합성
        fy, fx = frame.shape[:2]

        labelNum = len(labels)
        for i in range(labelNum):
            # row => 해당 행의 값들이 담겨있음
            row = cord[i]
            x = row[4]
            if x >= 0.2:
                # 0.5 * 1080 = 540 = x1
                x1 = int(row[0]*fx)
                y1 = int(row[1]*fy)
                x2 = int(row[2]*fx)
                y2 = int(row[3]*fy)

                # labelStr = f'{classNames[int(labels[i])]}, ({x1},{y1}), {str(row[4])[:4]}'
                labelStr = '{}, ({},{}), {}'.format(
                                classNames[int(labels[i])],
                                x1,y1,
                                str(row[4])[:4]
                            )
                
                cv2.rectangle(frame, (x1,y1,x2,y2), (0,255,0), 2)
                cv2.putText(frame, labelStr, 
                            (x1,y1), cv2.FONT_HERSHEY_SIMPLEX, 1, 
                            (0,0,255), 2)
                
        cv2.imshow('dst', frame)

    if cv2.waitKey(mfps) == 27:
        break

cap.release()
cv2.destroyAllWindows()
```

> 실행 결과

![캡처](https://github.com/ajhwan/OpenCV_study/assets/129160008/25fa391f-2140-47d7-b0d4-d3b693f59c30)

## 알고리즘
- 출처 : https://errorcode1001.tistory.com/10
  
###  DFS (Depth First Search)
> - DFS는 깊이 우선 탐색이라고 하며, 이름에 걸맞게 어떠한 그래프를 탐색할 때 최대한 깊숙히 탐색을 한 후, 더 탐색할 수 없으면 다른 경로를 탐색하는 알고리즘

- DFS의 순회 과정
  
![qweqwe](https://github.com/ajhwan/OpenCV_study/assets/129160008/4c9300b8-c58b-483a-a8a9-f51cfe833368)

1. A와 연결된 노드는 B와 C 입니다. A는 자신과 연결된 2개의 노드 중 어떤 노드를 선택할 지 고릅니다.
> - 두개의 노드 중 무엇을 선택해도 상관은 없습니다.
> - 저는 노드를 선택해야 할 경우, 그림에서 보았을 때 가장 위쪽에 선택하는 노드를 고르도록 하겠습니다.
> - ▶ 선택된 노드는 "B"입니다.

2. B와 연결된 노드 중 B보다 깊이가 깊은 노드는 D, E 입니다.
> - 저는 그림에서 보았을 때 가장 위쪽에 선택하는 노드 D를 고르겠습니다. 
> - ▶ 선택된 노드는 "D"입니다.

3. D와 연결된 노드 중 D보다 깊이가 깊은 노드는 없습니다. 
> - D에서 더 깊이 탐색을 하려고 해도 깊이가 더 깊은 노드가 없기 때문에 다시 B로 돌아옵니다.

4. B와 연결된 노드 중 B보다 깊이가 깊으며 아직 탐색하지 않은 노드는 E입니다.
> - ▶ 선택된 노드는 "E"입니다.

5. E와 연결된 노드 중 E보다 깊이가 깊으며 아직 탐색하지 않은 노드는 F와 G입니다.
> - 저는 그림에서 보았을 때 가장 위쪽에 선택하는 노드 G를 고르겠습니다. 
> - ▶ 선택된 노드는 "G"입니다.

6. G와 연결된 노드 중 G보다 깊이가 깊은 노드는 없습니다. 
> - G에서 더 깊이 탐색을 하려고 해도 깊이가 더 깊은 노드가 없기 때문에 다시 E로 돌아옵니다.

7. E와 연결된 노드 중 E보다 깊이가 깊으며 아직 탐색하지 않은 노드는 F입니다.
> - ▶ 선택된 노드는 "F"입니다.

8. F와 연결된 노드 중 F보다 깊이가 깊으며 아직 탐색하지 않은 노드는 없습니다. 
> - F에서 더 깊이 탐색을 하려고 해도 깊이가 더 깊은 노드가 없기 때문에 다시 E로 돌아옵니다.

9. E와 연결된 노드 중 아직 탐색을 하지 않은 노드는 없습니다.
> - 다시 B로 돌아옵니다.

10. B와 연결된 노드 중 아직 탐색을 하지 않은 노드는 없습니다.
> - 다시 A로 돌아옵니다.

11. A와 연결된 노드 중 A보다 깊이가 깊으며 아직 탐색하지 않은 노드는 C입니다.
> - ▶ 선택된 노드는 "C"입니다.
 
## DSF로 길찾기
```python
import time
import os

tile_map = [
    'ooooooooF',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'Soooooooo',
]

display_map = []


class Node:
    def __init__(self, x, y, parent = None):
        self.parent = parent
        self.x = x
        self.y = y

    def __eq__(self, __value: object) -> bool:
        return self.x == __value.x and self.y == __value.y
    
    def __str__(self) -> str:
        return f'Node({self.x},{self.y})'


startPos = (8,0)
finishTile = (0,8)

OFFSET_U = (-1,0)
OFFSET_D = (1,0)
OFFSET_L = (0,-1)
OFFSET_R = (0,1)

OFFSETS = [
    OFFSET_U,
    OFFSET_R,
    OFFSET_D,
    OFFSET_L,
]

def pathFinding():

    queue = []
    visited:list[Node] = []

    queue.append(Node(0, 8))

    while queue:

        currentNode = queue.pop(0)
        # print('currentNode: ', currentNode)
        visited.append(currentNode)

        for offset in OFFSETS:
            # print(offset)
            childX = currentNode.x + offset[1]
            childY = currentNode.y + offset[0]
            childNode = Node(childX, childY, currentNode)


            # 진행방향이 범위를 벗어났거나 장애물일 경우 무시
            if (0 > childX or childX > 8) or (0 > childY or childY > 8):
                continue

            if [vi for vi in visited if childNode == vi]:
                continue
                
            queue.append(childNode)
            break

    for vi in visited:
        os.system('cls')

        # 해당 노드를 지도에 표시
        displayMap(vi.x, vi.y)
        time.sleep(0.5)

def displayMap(nodeX,nodeY):
    for y, line in enumerate(tile_map):

        if y == nodeY:
            li = list(line)
            li[nodeX] = '@'
            tile_map[y] = ''.join(li)

        print(tile_map[y])


if __name__ == '__main__':
    pathFinding()
```

> 실행 결과

![adwdafaw](https://github.com/ajhwan/OpenCV_study/assets/129160008/bc86d4b9-f38e-44ed-9614-af44a621dda7)
![awefafeaefaewa](https://github.com/ajhwan/OpenCV_study/assets/129160008/53717e61-3c7c-4803-8416-3e5587b0f834)


### BFS (Breadth First Search)
> - BFS는 너비 우선 탐색이라고 하며, 이름에 걸맞게 어떠한 그래프를 탐색할 때 같은 깊이에 해당하는 노드부터 탐색하고 더 탐색할 수 없으면 더 깊은 노드들을 탐색하는 알고리즘

- BFS 순회 과정

![qwdaxw](https://github.com/ajhwan/OpenCV_study/assets/129160008/f6c908de-9971-4a2e-bbd0-07090d145094)

1. A와 연결된 노드는 B와 C 입니다. A는 자신과 연결된 2개의 노드 중 어떤 노드를 선택할 지 고릅니다.
> - 저는 노드를 선택해야 할 경우, 그림에서 보았을 때 가장 위쪽에 선택하는 노드를 고르도록 하겠습니다.
> - ▶ 선택된 노드는 "B"입니다.

2. B와 같은 깊이에 해당하는 노드는 C입니다.
> - ▶ 선택된 노드는 "C"입니다.

3. C와 같은 깊이에 해당하는 노드 중 탐색하지 않은 노드가 없습니다.
> - 더 깊은 곳을 탐색합니다.

4. 다음 깊이에 해당하는 노드는 D, E, F 입니다.
> - 제일 위쪽 노드인 D부터 탐색하겠습니다.
> - ▶ 선택된 노드는 "D"입니다.

5. D와 같은 깊이에 해당하는 노드는 E, F 입니다.
> - 저는 위쪽 노드인 E부터 탐색하겠습니다.
> - ▶ 선택된 노드는 "E"입니다.

6. 남은 노드인 F를 선택합니다.
> - ▶ 선택된 노드는 "F"입니다.

7. F와 같은 깊이에 해당하는 노드 중 탐색하지 않은 노드가 없습니다.
> - 더 깊은 곳을 탐색합니다.

8. 다음 깊이에 해당하는 노드는 G 입니다.
> - ▶ 선택된 노드는 "G"입니다.


## bfs로 길찾기
```python
import time
import os
from copy import deepcopy

tile_map = [
    'ooooooooF',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'ooooooooo',
    'Soooooooo',
]

class Node:
    def __init__(self, x, y, parent = None):
        self.parent = parent
        self.x = x
        self.y = y

    def __eq__(self, __value: object) -> bool:
        return self.x == __value.x and self.y == __value.y
    
    def __str__(self) -> str:
        return f'Node({self.x},{self.y})'


startPos = (8,0)
finishTile = (0,8)

finishNode = Node(8, 0)

OFFSET_U = (-1,0)
OFFSET_D = (1,0)
OFFSET_L = (0,-1)
OFFSET_R = (0,1)

OFFSETS = [
    OFFSET_U,
    OFFSET_R,
    OFFSET_D,
    OFFSET_L,
]

def pathFinding():

    global path

    queue = []
    visited:list[Node] = []

    # 시작위치를 넣어준다
    queue.append(Node(0, 8))

    while queue:

        currentNode = queue.pop(0)
        visited.append(currentNode)

        # S<-o<-o<-o<-o<-o<-o<-o<-F

        # 도착지점인지 확인
        # 도착지점이면 연결된 경로를 구성 종료
        if currentNode == finishNode:
            path = []

            pred = currentNode
            while pred is not None:
                path.append(pred)
                pred = pred.parent
            
            return


        for offset in OFFSETS:
            childX = currentNode.x + offset[1]
            childY = currentNode.y + offset[0]
            childNode = Node(childX, childY, currentNode)

            # 진행방향이 범위를 벗어났거나 장애물일 경우 무시
            if (0 > childX or childX > 8) or (0 > childY or childY > 8):
                continue

            if [vi for vi in visited if childNode == vi]:
                continue

            if [q for q in queue if childNode == q]:
                continue
            
            queue.append(childNode)


    # 방문한 순서대로 지도에 표시
    for vi in visited:
        os.system('cls')

        # 해당 노드를 지도에 표시
        displayMap(vi.x, vi.y)
        time.sleep(0.5)

def displayMap(nodeX,nodeY):

    map = deepcopy(tile_map)

    # 대입
    # li = [1,2,3]
    # li2 = li

    # 얕은복사
    # li3 = []
    # li3[:] = li[:]
    # li4 = li[:]

    # 깊은복사
    # li5 = deepcopy(li)

    for y, line in enumerate(map):

        if y == nodeY:
            li = list(line)
            li[nodeX] = '@'
            map[y] = ''.join(li)

        print(map[y])


def displayPath():
    # for p in path:
    #     print(p)

    map = deepcopy(tile_map)

    # 경로에 해당하는 타일의 값을 변경
    for node in path:
        line = map[node.y]
        li = list(line)
        li[node.x] = '*'
        map[node.y] = ''.join(li)
    
    for y, line in enumerate(map):
        print(line)

if __name__ == '__main__':
    pathFinding()

    # 시작부터 도착지점까지의 경로 출력
    displayPath()
```

> 실행 결과

![qdqwdaswq](https://github.com/ajhwan/OpenCV_study/assets/129160008/0fa2a8d7-e932-4c1e-8967-458e3028c9e8)



